# -*- coding: utf-8 -*-
"""Submission_Recommendation_System_Movie

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pix4VtiUVkfwKttOGMjUdB_FA6fETs0o

# **Proyek Sistem Rekomendasi**

* Nama : Moh. Aflah Azzaky
* Email : aflahazzaki123@gmail.com
* ID Dicoding : aflahazzaky
* Dataset : [Movie Recommendation Data](https://www.kaggle.com/datasets/rohan4050/movie-recommendation-data)

## **Data Understanding**

### **Import Library**

**Menginstall library yang dibutuhkan dalam pembuatan sistem rekomendasi film**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import os
import warnings
import keras
from keras import layers
warnings.filterwarnings('ignore')

from IPython.display import display, HTML
from zipfile import ZipFile
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors

"""### **Data Loading**

**Menginstall Kaggle dan mengunduh dataset**
"""

!pip install kaggle

os.environ['KAGGLE_KEY'] = 'bb18e594229a6d36e6251ef61baea580'
os.environ['KAGGLE_USERNAME'] = 'aflahazzaky'

!kaggle datasets download rohan4050/movie-recommendation-data
!unzip movie-recommendation-data.zip

"""## **Data Preprocessing**

**1. Membaca dataset yang telah diunduh dalam format csv**
"""

links_df = pd.read_csv('/content/ml-latest-small/links.csv')
movies_df = pd.read_csv('/content/ml-latest-small/movies.csv')
ratings_df = pd.read_csv('/content/ml-latest-small/ratings.csv')
tags_df = pd.read_csv('/content/ml-latest-small/tags.csv')

"""**2. Menampilkan dataset `links.csv`,`movies.csv`,`ratings.csv`, dan `tags.csv`**"""

# Fungsi untuk menampilkan DataFrame dengan judul dan jarak
def title_head(title, df):
    display(HTML(f"<h3>{title}</h3>"))  # Menambahkan judul
    display(df.head())  # Menampilkan DataFrame
    display(HTML("<br><hr><br>"))  # Menambahkan jarak dan garis pemisah

title_head('Links DataFrame', links_df)
title_head('Movies DataFrame', movies_df)
title_head('Ratings DataFrame', ratings_df)
title_head('Tags DataFrame', tags_df)

"""**3. Menampilkan data unik dari setiap dataset**"""

print('Jumlah `movieId` data unique dari links', len(links_df['movieId'].unique()))
print('Jumlah `movieId` data unique dari movies', len(movies_df['movieId'].unique()))
print('Jumlah `movieId` data unique dari ratings', len(ratings_df['movieId'].unique()))
print('Jumlah `movieId` data unique dari tags', len(tags_df['movieId'].unique()))
print('Jumlah `userId` data unique dari ratings', len(ratings_df['userId'].unique()))
print('Jumlah `userId` data unique dari tags', len(tags_df['userId'].unique()))

"""**4. Menampilkan variabel dataset `links.csv`,`movies.csv`,`ratings.csv`, dan `tags.csv`**"""

# Fungsi untuk menampilkan DataFrame dengan judul dan jarak
def title_info(title, df):
    display(HTML(f"<h3>{title}</h3>"))  # Menambahkan judul
    display(df.info())  # Menampilkan Info
    display(HTML("<br>"))  # Menambahkan jarak dan garis pemisah

title_info('Links Info', links_df)
title_info('Movies Info', movies_df)
title_info('Ratings Info', ratings_df)
title_info('Tags Info', tags_df)

"""**5. Menampilkan data kosong pada `links.csv`**"""

links_df.isnull().sum()

"""**6. Mencetak entri unik berdasarkan `movieId` dan jenis `genres`**"""

print('Banyak data entri unik berdasarkan `movieId` : ', movies_df['movieId'].nunique())
print('Jenis genre film : ', movies_df['genres'].unique())

"""**7. Mendeskripsikan variabel statisika dari `ratings`**"""

ratings_df.describe()

"""**8. Mencetak jumlah `userId`, `movieId`, dan `rating` pada dataset ratings**"""

print('Jumlah `userId` : ', len(ratings_df['userId'].unique()))
print('Jumlah `movieId` : ', len(ratings_df['movieId'].unique()))
print('Jumlah `rating` : ', len(ratings_df))

"""## **Data Preparation**

**1. Menggabungkan seluruh `movieId` pada kategori film**
"""

movies_all_df = np.concatenate((
    links_df['movieId'].unique(),
    movies_df['movieId'].unique(),
    ratings_df['movieId'].unique(),
    tags_df['movieId'].unique()
))

movies_all_df = np.sort(np.unique(movies_all_df))

print('Jumlah seluruh data film berdasarkan `movieId`: ', len(movies_all_df))

"""**2. Menggabungkan seluruh `userId` pada kategori film**"""

users_all_df = np.concatenate((
    ratings_df['userId'].unique(),
    tags_df['userId'].unique()
))

users_all_df = np.sort(np.unique(users_all_df))

print('Jumlah seluruh data pengguna berdasarkan `userId`: ', len(users_all_df))

"""**3. Menggabungkan file links, movies, ratings, dan tags**"""

movies_info_df = pd.concat([links_df, movies_df, tags_df])
movies_info_merge_df = pd.merge(ratings_df, movies_info_df, on='movieId', how='left')
movies_info_merge_df.head()

"""**4. Cek missing value dengan fungsi isnull()**"""

movies_info_merge_df.isnull().sum()

"""**5. Menghitung jumlah rating berdasarkan `movieId`**"""

movies_info_merge_df.groupby('movieId').sum()

"""**6. Menggabungkan seluruh data film dengan rating**"""

movies_all_rate_df = ratings_df
movies_all_rate_df

"""**7. Menggabungkan seluruh data film dengan data film berdasarkan `movieId`**"""

movies_all_name_df = pd.merge(movies_all_rate_df, movies_df[['movieId', 'title', 'genres']], on='movieId', how='left')
movies_all_name_df

"""**8. Menggabungkan seluruh data film dengan data tags berdasarkan `movieId`**"""

movies_all_data_df = pd.merge(movies_all_name_df, tags_df[['movieId', 'tag']], on='movieId', how='left')
movies_all_data_df

"""**9. Mengatasi missing value pada `movies_all_data_df`**"""

movies_all_data_df.isnull().sum()

"""**10. Membersihkan missing value menggunakan fungsi dropna()**"""

movies_all_data_clean_df = movies_all_data_df.dropna()
movies_all_data_clean_df.isnull().sum()

"""**11. Mengurutkan film berdasarkan `movieId`**"""

movies_fix_df = movies_all_data_clean_df.sort_values(by='movieId', ascending=True)
movies_fix_df

"""**12. Mengecek jumlah `movies_fix_df`**"""

len(movies_fix_df.tag.unique())

"""**13. Membuat variabel `movies_preparation_df` yang berisi `movies_fix_df` kemudian mengurutkan berdasarkan `movieId`**"""

movies_preparation_df = movies_fix_df
movies_preparation_df.sort_values(by='movieId')

"""**14. Membuang data duplikat pada variabel `movies_preparation_df`**"""

movies_preparation_df = movies_preparation_df.drop_duplicates('movieId')
movies_preparation_df

"""**15. Mengonversi data series menjadi dalam bentuk list**"""

movies_id = movies_preparation_df['movieId'].tolist()
movies_title = movies_preparation_df['title'].tolist()
movies_genre = movies_preparation_df['genres'].tolist()

print(len(movies_id))
print(len(movies_title))
print(len(movies_genre))

"""**16. Membuat dictionary**"""

# Membuat dictionary untuk data `movieId`, `title`, dan `genre`
movies_dict = pd.DataFrame({
    'movieId' : movies_id,
    'title' : movies_title,
    'genres' : movies_genre
})

movies_dict

"""## **Model Development**

### **Content Based Filtering**

**1. Cek data dari `movies_dict`**
"""

movies_data = movies_dict
movies_data.sample(5)

"""**2. Inisialisasi TfidVectorizer dan melakukan perhitungan pada genres lalu mapping array**"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada movies_data genres
tf.fit(movies_data['genres'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""**3. Melakukan fit transformasi matrix**"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(movies_data['genres'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""**4. Mengubah vektor tf-idf ke matriks dengan fitur todense()**"""

tfidf_matrix.todense()

"""**5. Membuat dataframe untuk melihat tf-idf matrix**"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=movies_data.title
).sample(10, axis=1).sample(10, axis=0)

"""**6. Menghitung cosine similarity pada matrix tf-idf**"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""**7. Membuat variabel cosine_similarity**"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movies_data['title'], columns=movies_data['title'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""**8. Membuat fungsi rekomendasi film**"""

def movies_recommendation(title, similarity_data=cosine_sim_df, items=movies_data[['title', 'genres']], k=5):
  index = similarity_data.loc[:,title].to_numpy().argpartition(range(-1,-k,-1))
  closest = similarity_data.columns[index[-1:-(k+2):-1]]
  closest = closest.drop(title, errors='ignore')
  return pd.DataFrame(closest).merge(items).head(k)

"""**9. Mendapatkan rekomendasi film**"""

movies_recommendation('Superman II (1980)')

"""### **Collaborative Filtering**

**1. Membaca dataset**
"""

ratings = ratings_df
ratings

"""**2. Encode pada data user**"""

# Mengubah userId menjadi list tanpa nilai yang sama
user_id = ratings['userId'].unique().tolist()
print('List user id', user_id)

# Melakukan encoding userId
user2user_encoded = {x: i for i, x in enumerate(sorted(user_id))}
print('Encoding user id', user2user_encoded)

# Melakukan proses encoding angka ke ke userId
user_encoded_to_user = {i: x for i, x in enumerate(sorted(user_id))}
print('Encoding angka ke userId', user_encoded_to_user)

"""**3.  Encode pada data title**"""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_id = ratings['movieId'].unique().tolist()
print('List movie id', movie_id)

# Melakukan encoding movieId
movie2movie_encoded = {x: i for i, x in enumerate(sorted(movie_id))}
print('Encoding movie id', movie2movie_encoded)

# Melakukan proses encoding angka ke ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(sorted(movie_id))}
print('Encoding angka ke movieId', movie_encoded_to_movie)

"""**4. Mempetakan userId dan movieId**"""

# Mapping userId ke dataframe user
ratings['user'] = ratings['userId'].map(user2user_encoded)
ratings

# Mapping movieId ke dataframe movie
ratings['movie'] = ratings['movieId'].map(movie2movie_encoded)
ratings

"""**5. Cek data mapping**"""

# Mendapatkan jumlah user
num_users = len(user2user_encoded)
print(num_users)

# Mendapatkan jumlah movie
num_movies = len(movie_encoded_to_movie)
print(num_movies)

# Mengubah rating menjadi nilai float
ratings['rating'] = ratings['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(ratings['rating'])

# Nilai maksimal rating
max_rating = max(ratings['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movies, min_rating, max_rating
))

"""**6. Acak data untuk training dan test**"""

train_test_df = ratings.sample(frac=1, random_state=42)
train_test_df

"""**7. Membagi data untuk train test**"""

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = train_test_df[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = train_test_df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * train_test_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""## **Training Process**

**1. Membuat class RecommenderNet**
"""

import tensorflow as tf
import keras
from keras import layers

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movies, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movies = num_movies
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movies_embedding = layers.Embedding( # layer embeddings movies
        num_movies,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movies_bias = layers.Embedding(num_movies, 1) # layer embedding movies bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movies_vector = self.movies_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movies_bias = self.movies_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movies = tf.tensordot(user_vector, movies_vector, 2)

    x = dot_user_movies + user_bias + movies_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""**2. Melakukan proses compile terhadap model**"""

model = RecommenderNet(num_users, num_movies, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""**3. Melakukan proses training**"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""**4. Menampilkan plot evaluasi**"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Plot di atas menunjukkan nilai *root mean squared error* (RMSE) dari data latih (train) dan data uji (test) seiring bertambahnya *epoch*. Awalnya, RMSE pada kedua data menurun, menunjukkan model belajar dengan baik. Namun, setelah *epoch* 10-20, RMSE pada data uji mulai stabil dan sedikit meningkat, sementara RMSE pada data latih terus menurun. Ini adalah tanda *overfitting*, di mana model hanya bekerja baik pada data latih, tetapi tidak pada data uji. Untuk mengatasi hal ini, metode seperti *regularization*, *dropout*, atau *early stopping* dapat diterapkan agar model lebih baik dalam menggeneralisasi data baru.

**5. Mendapatkan rekomendasi film**
"""

data_df = movies_dict
df = pd.read_csv('/content/ml-latest-small/ratings.csv')

# Mengambil sample user
user_id = df.userId.sample(1).iloc[0]
movies_watched_by_user = df[df.userId == user_id]

movies_not_watched = data_df[~data_df['movieId'].isin(movies_watched_by_user.movieId.values)]['movieId']
movies_not_watched = list(set(movies_not_watched).intersection(set(movie2movie_encoded.keys())))
movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]
user_encoder = user2user_encoded.get(user_id)
user_movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))

ratings = model.predict(user_movie_array).flatten()
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [movie_encoded_to_movie[movies_not_watched[i][0]] for i in top_ratings_indices]

print(f'Menampilkan rekomendasi untuk pengguna: {user_id}')
print('=' * 32)
print('Film dengan rating tinggi dari pengguna')
print('-' * 32)

# Menampilkan 5 film dengan rating tertinggi dari pengguna
top_movies_user = movies_watched_by_user.nlargest(5, 'rating').movieId.values
for _, row in movies_df[movies_df['movieId'].isin(top_movies_user)].iterrows():
    print(f"{row.title} : {row.genres}")

print('-' * 32)
print('10 film teratas yang direkomendasikan')
print('-' * 32)

# Menampilkan 10 film teratas yang direkomendasikan
for _, row in movies_df[movies_df['movieId'].isin(recommended_movie_ids)].iterrows():
    print(f"{row.title} : {row.genres}")

# Membuat tabel untuk film dengan rating tertinggi dari pengguna
top_movies_user_df = movies_df[movies_df['movieId'].isin(top_movies_user)][['title', 'genres']]
print(f'Menampilkan rekomendasi untuk pengguna: {user_id}')
print('=' * 50)
print('Film dengan rating tertinggi dari pengguna:')
print('-' * 50)
print(top_movies_user_df.to_string(index=False))

print('\n' + '-' * 50)
print('10 film teratas yang direkomendasikan:')
print('-' * 50)

# Membuat tabel untuk 10 film teratas yang direkomendasikan
recommended_movies_df = movies_df[movies_df['movieId'].isin(recommended_movie_ids)][['title', 'genres']]
print(recommended_movies_df.to_string(index=False))